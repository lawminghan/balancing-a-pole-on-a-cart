{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yue-zhongqi/cartpole_colab/blob/main/cartpole.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0R60XKMakME_"
      },
      "source": [
        "# Reinforcement Learning Challenge: Balancing a Pole on a Cart\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZauhjPSfX7pI"
      },
      "source": [
        "# Tutorial and Sample Code for Balancing a Pole on a Cart"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBiYOoesYMvr"
      },
      "source": [
        "## Installing dependencies:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbgnVwZmX5uW",
        "outputId": "7d05cc90-3335-46b1-aacd-8bfc14dc4a0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gym[classic_control] in /usr/local/lib/python3.9/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.9/dist-packages (from gym[classic_control]) (1.22.4)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.9/dist-packages (from gym[classic_control]) (6.1.0)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.9/dist-packages (from gym[classic_control]) (0.0.8)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.9/dist-packages (from gym[classic_control]) (2.2.1)\n",
            "Requirement already satisfied: pygame==2.1.0 in /usr/local/lib/python3.9/dist-packages (from gym[classic_control]) (2.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.8.0->gym[classic_control]) (3.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (67.6.1)\n"
          ]
        }
      ],
      "source": [
        "!apt-get install -y xvfb python-opengl > /dev/null 2>&1\n",
        "!pip install gym pyvirtualdisplay > /dev/null 2>&1\n",
        "!pip install gym pyvirtualdisplay > /dev/null 2>&1\n",
        "!apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1\n",
        "!pip install gym[classic_control]\n",
        "!apt-get update > /dev/null 2>&1\n",
        "!apt-get install cmake > /dev/null 2>&1\n",
        "!pip install --upgrade setuptools 2>&1\n",
        "!pip install ez_setup > /dev/null 2>&1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwKbYeTgbaTA"
      },
      "source": [
        "## Importing dependencies and define helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {
        "id": "j6KpgCLGYWmj"
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "from gym import logger as gymlogger\n",
        "from gym.wrappers import RecordVideo\n",
        "gymlogger.set_level(40) #error only\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import math\n",
        "import glob\n",
        "import io\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "from IPython import display as ipythondisplay\n",
        "\n",
        "def show_video():\n",
        "  mp4list = glob.glob('video/*.mp4')\n",
        "  if len(mp4list) > 0:\n",
        "    mp4 = mp4list[0]\n",
        "    video = io.open(mp4, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n",
        "                loop controls style=\"height: 400px;\">\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))))\n",
        "  else: \n",
        "    print(\"Could not find video\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehbqP9CXbmo7"
      },
      "source": [
        "## Tutorial: Loading CartPole environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {
        "id": "Go12dH4qbwBy"
      },
      "outputs": [],
      "source": [
        "env = gym.make(\"CartPole-v1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XZ9g3xrcAXE"
      },
      "source": [
        "We can check the action and observation space of this environment. Discrete(2) means that there are two valid discrete actions: 0 & 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytxvVmLdcRyw",
        "outputId": "188b262f-736b-423e-b1cf-fb789dd74bfd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discrete(2)\n"
          ]
        }
      ],
      "source": [
        "print(env.action_space)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVXGWi_Ncfg-"
      },
      "source": [
        "The observation space is given below. The first two arrays define the min and max values of the 4 observed values, corresponding to cart position, velocity and pole angle, angular velocity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DyqHr9I5cdkX",
        "outputId": "6de2fc41-ef8a-4e81-cea8-541ca4405dd3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)\n"
          ]
        }
      ],
      "source": [
        "print(env.observation_space)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFOdaU2Gdyg0"
      },
      "source": [
        "We call each round of the pole-balancing game an \"episode\". At the start of each episode, make sure the environment is reset, which chooses a random initial state, e.g., pole slightly tilted to the right. This initialization can be achieved by the code below, which returns the observation of the initial state."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMr6qAqxdOsm",
        "outputId": "a98cd31d-3071-437b-fa1f-b9eb800ef970"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial observations: [ 0.02803358 -0.04482078 -0.04145035  0.02407717]\n"
          ]
        }
      ],
      "source": [
        "observation = env.reset()\n",
        "print(\"Initial observations:\", observation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnG2QdfbeZrI"
      },
      "source": [
        "For the CartPole environment, there are two possible actions: 0 for pushing to the left and 1 for pushing to the right. For example, we can push the cart to the left using code below, which returns the new observation, the current reward, an indicator of whether the game ends, and some additional information (not used in this project). For CartPole, the game ends when the pole is significantly tilted or you manage to balance the pole for 500 steps. You get exactly 1 reward for each step before the game ends (i.e., max cumulative reward is 500)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmfMDvyYdWGk",
        "outputId": "afd4cc68-62ff-4065-f6d5-433e37f14ff9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New observations after choosing action 0: [ 0.02713716 -0.23932454 -0.04096881  0.3033993 ]\n",
            "Reward for this step: 1.0\n",
            "Is this round done? False\n"
          ]
        }
      ],
      "source": [
        "observation, reward, done, info = env.step(0)\n",
        "print(\"New observations after choosing action 0:\", observation)\n",
        "print(\"Reward for this step:\", reward)\n",
        "print(\"Is this round done?\", done)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tj0zCh59fhBb"
      },
      "source": [
        "Now we can play a full round of the game using a naive strategy (always choosing action 0), and show the cumulative reward in the round. Note that reward returned by env.step(*) corresponds to the reward for current step. So we have to accumulate the reward for each step. Clearly, the naive strategy performs poorly by surviving only a dozen of steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVucQVRwf6Jm",
        "outputId": "934ef1c5-8ea9-4a3b-d126-a3e0df972526"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cumulative reward for this round: 10.0\n"
          ]
        }
      ],
      "source": [
        "observation = env.reset()\n",
        "cumulative_reward = 0\n",
        "done = False\n",
        "while not done:\n",
        "    observation, reward, done, info = env.step(0)\n",
        "    cumulative_reward += reward\n",
        "print(\"Cumulative reward for this round:\", cumulative_reward)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oIzK9SzhlWN"
      },
      "source": [
        "## Task 1: Development of an RL agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvX0HOXnegwU"
      },
      "source": [
        "# RL Agent : Q-Learning\n",
        "\n",
        "Before we begin training our Q-Learning agent, we need to first define the state space, action space and reward function. \n",
        "\n",
        "### Action Space\n",
        "The action was defined as {0,1}, which indicates left or right respectively. \n",
        "\n",
        "### State Space\n",
        "However, the state space will need to be further defined. From the table below, we can see that the observation space consists of continuous values, which means there are infinite possible states. Therefore, we will need to convert these continuous values into ranges that represent discrete states.\n",
        "\n",
        "| Num | Observation | Min | Max |\n",
        "| --- | --- | --- | --- | \n",
        "| 0 | Cart Position | -4.8 | 4.8 |\n",
        "| 1 | Cart Velocity | -Inf | Inf |\n",
        "| 2 | Pole Angle | -0.418 rad | 0.418 rad |\n",
        "| 3 | Pole Angular Velocity | -Inf | Inf  |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {
        "id": "C3BaHbVbcN0y"
      },
      "outputs": [],
      "source": [
        "def get_bins(cart_position_bin_size, cart_velocity_bin_size, pole_angle_bin_size, pole_angular_velocity_bin_size):\n",
        "  # Defining the ranges for each type of observation.\n",
        "  min_cart_position, max_cart_position = -2.4, 2.4                  # Game terminates beyond this range\n",
        "  min_cart_velocity, max_cart_velocity = -1.2, 1.2                  # Values beyond this range are too big, and can be all grouped into a state\n",
        "  min_pole_angle, max_pole_angle = -0.209, 0.209                    # Game terminates beyond this range\n",
        "  min_pole_angular_velocity, max_pole_angular_velocity = -1.2, 1.2  # Values beyond this range are too big, and can be all grouped into a state\n",
        "\n",
        "  bins = [\n",
        "      np.linspace(min_cart_position, max_cart_position, cart_position_bin_size-1),\n",
        "      np.linspace(min_cart_velocity, max_cart_velocity, cart_velocity_bin_size-1),\n",
        "      np.linspace(min_pole_angle, max_pole_angle, pole_angle_bin_size-1),\n",
        "      np.linspace(min_pole_angular_velocity, max_pole_angular_velocity, pole_angular_velocity_bin_size-1)\n",
        "  ]\n",
        "  return bins"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8XmRGtBvznm"
      },
      "source": [
        "This `get_bins()` function takes in 4 values, which represents the bin size of each observation type. \n",
        "We define the range of each observation type is defined as follows:\n",
        "\n",
        "| Num | Observation | Lower Boundary | Upper Boundary | Reason |\n",
        "| --- | --- | --- | --- | --- |\n",
        "| 0 | Cart Position | -2.4 | 2.4 | Game ends beyond this range |\n",
        "| 1 | Cart Velocity | -1.2 | 1.2 | Although the range is to infinity, values beyond +-1.2 would lead to termination of the game as the velocity is too high |\n",
        "| 2 | Pole Angle | -0.209 rad | 0.209 rad | Game ends beyond this range |\n",
        "| 3 | Pole Angular Velocity | -1.2 | 1.2  | Although the range is to infinity, values beyond +-1.2 would lead to termination of the game as the velocity is too high |\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbpGM_ta1x1j",
        "outputId": "23b23e65-c971-45f6-ba04-f92538d3faf4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cart Position: \t\t [-2.4 -1.2  0.   1.2  2.4]\n",
            "Cart Velocity: \t\t [-1.2 -0.8 -0.4  0.   0.4  0.8  1.2]\n",
            "Pole Angle: \t\t [-0.209   -0.15675 -0.1045  -0.05225  0.       0.05225  0.1045   0.15675\n",
            "  0.209  ]\n",
            "Pole Angular Velocity: \t [-1.2 -0.8 -0.4  0.   0.4  0.8  1.2]\n"
          ]
        }
      ],
      "source": [
        "observation_bins = get_bins(6, 8, 10, 8)\n",
        "print(\"Cart Position: \\t\\t\", observation_bins[0])\n",
        "print(\"Cart Velocity: \\t\\t\", observation_bins[1])\n",
        "print(\"Pole Angle: \\t\\t\", observation_bins[2])\n",
        "print(\"Pole Angular Velocity: \\t\", observation_bins[3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUJOAUDY1ro9"
      },
      "source": [
        "The cell above shows the bins if we split the observation space into 6, 8, 10, 8 bins respectively.\n",
        "\n",
        "To account for the symmetry of the game around its centre and the fact that direction matters in this game, we divided the value range into an even number of bins. This guarantees that there are an equal number of bins representing the left direction (where the values are less than or equal to 0) and the right direction (where the values are greater than 0), such that there are no bin that has values that represent different directions.\n",
        "\n",
        "Another factor to consider is the number of bins for each observation type. If there are too few bins, a single state would encompass a large value range, leading to a huge variance. Conversely, if there are too many bins, it would require a large number of episodes to achieve convergence. To strike a balance, we conducted some testing and decided to partition `Cart Position` into 6 bins, `Cart Velocity` and `Pole Angular Velocity` into 8 bins. However, for `Pole Angle`, which we deemed a critical observation requiring more sensitivity and precision (as the goal is to balance the pole), we opted to split it into 10 bins.\n",
        " \n",
        "Here's how to intepret the bins \n",
        "\n",
        "Example: \n",
        "> `Cart Position` is separated into the following 6 bins.\n",
        "\n",
        "| Bin | Lower Boundary (<=) | Upper Boundary (<) | \n",
        "| --- | --- | --- |\n",
        "| 0 | -inf | -2.4 |\n",
        "| 1 | -2.4 | -1.2 |\n",
        "| 2 | -1.2 | 0 |\n",
        "| 3 | 0 | 1.2 |\n",
        "| 4 | 1.2 | 2.4 |\n",
        "| 5 | 2.4 | inf |\n",
        "\n",
        "> `Cart Velocity` is separated into the following 8 bins.\n",
        "\n",
        "| Bin | Lower Boundary (<=) | Upper Boundary (<) | \n",
        "| --- | --- | --- |\n",
        "| 0 | -inf | -1.2 |\n",
        "| 1 | -1.2 | -0.8 |\n",
        "| 2 | -0.8 | -0.4 |\n",
        "| 3 | -0.4 | 0 |\n",
        "| 4 | 0 | 0.4 |\n",
        "| 5 | 0.4 | 0.8 |\n",
        "| 6 | 0.8 | 1.2 |\n",
        "| 7 | 1.2 | inf |\n",
        "\n",
        " \n",
        "> `Pole Angle` is split into the following 10 bins.\n",
        "\n",
        "| Bin | Lower Boundary (<=) | Upper Boundary (<) | \n",
        "| --- | --- | --- |\n",
        "| 0 | -inf | -0.209 |\n",
        "| 1 | -0.209 | -0.15675 |\n",
        "| 2 | -0.15675 | -0.1045 |\n",
        "| 3 | -0.1045 | -0.05225 |\n",
        "| 4 | -0.05225 | 0 |\n",
        "| 5 | 0 | 0.05225 |\n",
        "| 6 | 0.05225 | 0.1045 |\n",
        "| 7 | 0.1045 | 0.15675 |\n",
        "| 8 | 0.15675 | 0.209 |\n",
        "| 9 | 0.209 | inf |\n",
        "\n",
        "> `Pole Angular Velocity` is separated into the following 8 bins.\n",
        "\n",
        "| Bin | Lower Boundary (<=) | Upper Boundary (<) | \n",
        "| --- | --- | --- |\n",
        "| 0 | -inf | -1.2 |\n",
        "| 1 | -1.2 | -0.8 |\n",
        "| 2 | -0.8 | -0.4 |\n",
        "| 3 | -0.4 | 0 |\n",
        "| 4 | 0 | 0.4 |\n",
        "| 5 | 0.4 | 0.8 |\n",
        "| 6 | 0.8 | 1.2 |\n",
        "| 7 | 1.2 | inf |\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {
        "id": "uB5Ay6kYj3On"
      },
      "outputs": [],
      "source": [
        "def discrete_states(observation, bins):\n",
        "  state_idx = []\n",
        "  for i in range(len(observation)):\n",
        "    state_idx.append(np.digitize(observation[i], bins[i])) # Assigns each observation into a bin\n",
        "\n",
        "  return tuple(state_idx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmMnBCB6zJfR"
      },
      "source": [
        "The function `discrete_states()` takes the provided bins and uses them to discretize the continuous observation space. The function returns a tuple of indices that correspond to the state for each observation. \n",
        "\n",
        "For instance, the observation [-0.02004853 0.0182426 0.00702342 0.02360607] will be converted to the tuple of indices (2, 4, 5, 4). These indices can then be used to access the Q-table and retrieve the Q-values associated with this particular state.\n",
        "\n",
        "---\n",
        "\n",
        "### Total Number of States and State-Action pairs\n",
        "\n",
        "Given that we have partitioned the 4 observations into 6, 8, 10, 8 bins, respectively, we now have a total of 3,840 unique states. Consequently, we have a total of 7,680 state-action pairs in the Q-table.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhQrgNf_5UZ8"
      },
      "source": [
        "# Q-Learning Policy\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lISv66Z2NI2n"
      },
      "source": [
        "### Reward function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {
        "id": "5wCyYderMeh7"
      },
      "outputs": [],
      "source": [
        "def reward_function(done, steps, target_steps):\n",
        "    # Early termination: The game is done before target_steps were reached.\n",
        "    if done and steps < target_steps:\n",
        "      reward = -1\n",
        "    else:\n",
        "      reward = 0\n",
        "    return reward"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPYFGbqnMmhA"
      },
      "source": [
        "Now that the state and action space are defined, we need to define the reward function. \n",
        "\n",
        "The default reward function assigns a reward of 1 to every step, which is nonoptimal. This is because both favourable and unfavourable actions receive the same reward of 1, which is not appropriate.\n",
        "\n",
        "To improve the reward function, we decided to introduce penalties for actions that lead to an early termination of the game instead, as the ultimate goal of the game is to survive as long as possible and reach 500 steps. Specifically, state-action pairs that result in early termination will now receive a reward of -1, while those that do not result in early termination will receive a reward of 0.\n",
        "\n",
        "By assigning a penalty of -1 to the state-action pairs that lead to early termination, we can update these state-action pairs and propagate the negative values to the state-actions that led to the unfavourable state. Hence, the more negative the value associated with a state-action pair, the more unfavourable that state-action is considered to be. This approach helps the agent to learn to avoid actions that lead to an early termination and encourages it to select actions that lead to a longer survival time.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GE7zne_cMaII"
      },
      "source": [
        "### Training process\n",
        "\n",
        "First, we declare our parameters and set up the environemnt.\n",
        "\n",
        "Then, we will loop over as many episodes as needed to train our Q-Learning Agent until it converges.\n",
        "\n",
        "In each episode, we will update the the `Q-table` using the Q-Learning equation, where the Q-value of the current state-action pair is updated by adding the learning rate times the difference between the new sample (reward and discounted maximum Q-value of the next state) and the old Q-value estimation.\n",
        "\n",
        "At the end of each episode, if the criteria for convergence has been achieved, training will stop.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### Parameters\n",
        "\n",
        "| parameters | value | reason |\n",
        "| --- | --- | --- |\n",
        "| cart_position_bin_size | 6 | Decided from trial-and-error |\n",
        "| cart_velocity_bin_size | 8 | Decided from trial-and-error |\n",
        "| pole_angle_bin_size | 10 | Decided from trial-and-error |\n",
        "| pole_angular_velocity_bin_size | 8 | Decided from trial-and-error |\n",
        "| learning_rate | 0.1 | Decided from trial-and-error |\n",
        "| discount_factor | 0.99 | Future states are highly important as the goal is to survive in the future |\n",
        "| exploration_rate | 0.25-0.01 | probability that the agent will select a random action (explore) rather than the action with the highest Q-value (exploit) for a given state  |\n",
        "| target_steps | 500 | This is the goal that we want to achieve. Early termination before `target_steps` are given -1 reward |\n",
        "| target_consecutive_success | 100 | Criteria for convergence. 100 consecutive episode successes needed to stop training. |\n",
        "\n",
        "\n",
        "### Epsilon Decay\n",
        "Additionally, our group decided to add in epsilon decay, which is a technique to gradually reduce the exploration rate over time during training. The idea behind this technique is to start with high exploration rates at the beginning of the training, where the agent needs to explore the environment to learn about the optimal policies. As the training progresses, the exploration rate is gradually reduced to prioritize the exploitation of the already learned policies. \n",
        "\n",
        "Linear Epsilon Decay:\n",
        "- Initial exploration rate is 0.25. \n",
        "- Decreases by 0.01 for every 100 episodes until 0.01.\n",
        "\n",
        "\n",
        "### Note: The training should be completed within 3 minutes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 204,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQKEC149Ys03",
        "outputId": "d9effaf0-aa10-498f-edc2-d348839bd652"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode  100:\t 29 steps.\tAvg of last 100 episodes:\t50.87\n",
            "Episode  100 exploration rate: 0.24\n",
            "Episode  200:\t212 steps.\tAvg of last 100 episodes:\t165.96\n",
            "Episode  200 exploration rate: 0.23\n",
            "Episode  300:\t 12 steps.\tAvg of last 100 episodes:\t119.51\n",
            "Episode  300 exploration rate: 0.22\n",
            "Episode  400:\t240 steps.\tAvg of last 100 episodes:\t156.73\n",
            "Episode  400 exploration rate: 0.21\n",
            "Episode  500:\t290 steps.\tAvg of last 100 episodes:\t228.93\n",
            "Episode  500 exploration rate: 0.20\n",
            "Episode  600:\t354 steps.\tAvg of last 100 episodes:\t308.93\n",
            "Episode  600 exploration rate: 0.19\n",
            "Episode  700:\t192 steps.\tAvg of last 100 episodes:\t264.88\n",
            "Episode  700 exploration rate: 0.18\n",
            "Episode  800:\t279 steps.\tAvg of last 100 episodes:\t321.66\n",
            "Episode  800 exploration rate: 0.17\n",
            "Episode  900:\t224 steps.\tAvg of last 100 episodes:\t330.54\n",
            "Episode  900 exploration rate: 0.16\n",
            "Episode 1000:\t350 steps.\tAvg of last 100 episodes:\t250.64\n",
            "Episode 1000 exploration rate: 0.15\n",
            "Episode 1100:\t223 steps.\tAvg of last 100 episodes:\t262.91\n",
            "Episode 1100 exploration rate: 0.14\n",
            "Episode 1200:\t244 steps.\tAvg of last 100 episodes:\t295.04\n",
            "Episode 1200 exploration rate: 0.13\n",
            "Episode 1300:\t469 steps.\tAvg of last 100 episodes:\t307.85\n",
            "Episode 1300 exploration rate: 0.12\n",
            "Episode 1400:\t500 steps.\tAvg of last 100 episodes:\t468.42\n",
            "Episode 1400 exploration rate: 0.11\n",
            "Episode 1500:\t309 steps.\tAvg of last 100 episodes:\t336.45\n",
            "Episode 1500 exploration rate: 0.10\n",
            "Episode 1600:\t500 steps.\tAvg of last 100 episodes:\t384.16\n",
            "Episode 1600 exploration rate: 0.09\n",
            "Episode 1700:\t328 steps.\tAvg of last 100 episodes:\t324.86\n",
            "Episode 1700 exploration rate: 0.08\n",
            "Episode 1800:\t500 steps.\tAvg of last 100 episodes:\t448.13\n",
            "Episode 1800 exploration rate: 0.07\n",
            "Episode 1900:\t176 steps.\tAvg of last 100 episodes:\t388.36\n",
            "Episode 1900 exploration rate: 0.06\n",
            "Episode 2000:\t500 steps.\tAvg of last 100 episodes:\t432.36\n",
            "Episode 2000 exploration rate: 0.05\n",
            "Episode 2100:\t500 steps.\tAvg of last 100 episodes:\t483.48\n",
            "Episode 2100 exploration rate: 0.04\n",
            "Episode 2200:\t500 steps.\tAvg of last 100 episodes:\t447.03\n",
            "Episode 2200 exploration rate: 0.03\n",
            "Episode 2287: Policy has converged with 100 consecutive success.\n"
          ]
        }
      ],
      "source": [
        "# Q-Learning to generate Q-table\n",
        "\n",
        "# Parameters\n",
        "cart_position_bin_size, cart_velocity_bin_size, pole_angle_bin_size, pole_angular_velocity_bin_size = 6, 8, 10, 8\n",
        "\n",
        "learning_rate = 0.1\n",
        "discount_factor = 0.99\n",
        "exploration_rate = 0.25\n",
        "target_steps = 500\n",
        "target_consecutive_success = 100\n",
        "\n",
        "# Create bins\n",
        "bins = get_bins(cart_position_bin_size, cart_velocity_bin_size, pole_angle_bin_size, pole_angular_velocity_bin_size)\n",
        "\n",
        "# Create Q-table with all zeroes. \n",
        "Q_table = np.zeros(shape=(cart_position_bin_size, cart_velocity_bin_size, pole_angle_bin_size, pole_angular_velocity_bin_size, 2))\n",
        "\n",
        "# Set up environment\n",
        "env = gym.make(\"CartPole-v1\")\n",
        "\n",
        "results = []\n",
        "consecutive_success = 0\n",
        "episode = 0\n",
        "\n",
        "# Iterate over each episode until convergence\n",
        "while True:\n",
        "  \n",
        "  # Reset the environment for a new episode\n",
        "  observation = env.reset()\n",
        "  current_state = discrete_states(observation, bins)\n",
        "  done = False\n",
        "  episode += 1\n",
        "  steps = 0\n",
        "\n",
        "  # Iterate over each step and update Q-table\n",
        "  while not done:\n",
        "    # Choose an action using epsilon-greedy policy\n",
        "    if np.random.uniform(0,1) < exploration_rate:\n",
        "      action = env.action_space.sample()          # Exploration: Probability of `exploration_rate` to randomly choose an action from the action space of (0,1)\n",
        "    else:\n",
        "      action = np.argmax(Q_table[current_state])  # Exploitation: Probability of 1-`exploration_rate` to choose action that gives the highest Q-value from q_table\n",
        "    observation, reward, done, info = env.step(action)\n",
        "    next_state = discrete_states(observation, bins)\n",
        "    steps += 1\n",
        "\n",
        "    # Assign reward based on reward function\n",
        "    reward = reward_function(done=done, \n",
        "                             steps=steps, \n",
        "                             target_steps=target_steps\n",
        "                             )\n",
        "\n",
        "\n",
        "    # Max Q-value of the next state\n",
        "    max_Q_of_next_state = np.max(Q_table[next_state]) \n",
        "\n",
        "    # Old Q-value of current state-action pair\n",
        "    old_Q_of_current_state_action_pair = Q_table[current_state][action]\n",
        "\n",
        "    # Update the Q-value for the current state-action pair\n",
        "    Q_table[current_state][action] += learning_rate * (reward + discount_factor * max_Q_of_next_state - old_Q_of_current_state_action_pair)\n",
        "\n",
        "    # Update the state\n",
        "    current_state = next_state\n",
        "  \n",
        "\n",
        "# At the end of an episode\n",
        "  # Print the episode number and avg reward of the past 100 episodes\n",
        "  results.append(steps)\n",
        "  if episode % 100 == 0:\n",
        "    past_100_avg = np.array(results).mean()\n",
        "    print(\"Episode {:4}:\\t{:3} steps.\\tAvg of last 100 episodes:\\t{:4}\".format(episode, steps, past_100_avg))\n",
        "    results =[]\n",
        "\n",
        "    # Linear Epsilon Decay\n",
        "    if exploration_rate > 0.01:\n",
        "      exploration_rate -= 0.01 \n",
        "      print(\"Episode {:4} exploration rate: {:.2f}\".format(episode, exploration_rate))\n",
        "\n",
        "\n",
        "  # End training when Q-table has converged\n",
        "  if steps >= target_steps:\n",
        "    consecutive_success +=1\n",
        "  else:\n",
        "    consecutive_success = 0\n",
        "  if consecutive_success >= target_consecutive_success:\n",
        "    print(\"Episode {:4}: Policy has converged with {} consecutive success.\".format(episode, target_consecutive_success))\n",
        "    break\n",
        "  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 205,
      "metadata": {
        "id": "x4bx0CFPYFSG"
      },
      "outputs": [],
      "source": [
        "def Q_Learning_RL_Agent(observation):\n",
        "    # Use learned Q-table to return an action\n",
        "    current_state = discrete_states(observation, bins)\n",
        "    return np.argmax(Q_table[current_state])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMdoMxpw0Xwo"
      },
      "source": [
        "The `Q_Learning_RL_Agent` can now use the `Q_table` to play the game. It can do this by first converting the observation into a discrete state and then using the current_state to index the relevant `Q_table` entry. From this entry, the action with the maximum Q-value for that state can be determined using `np.argmax()`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAi7KKwNiegR"
      },
      "source": [
        "For Task 1, we can show the observation and chosen action below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 206,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae2ia-vUiNKJ",
        "outputId": "2759496a-fb36-4c6b-bf64-1ecf1a16a026"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Observation: [-0.04586409 -0.00418321  0.02016653 -0.03933192]\n",
            "Chosen action: 0\n"
          ]
        }
      ],
      "source": [
        "observation = env.reset()\n",
        "action = Q_Learning_RL_Agent(observation)\n",
        "print(\"Observation:\", observation)\n",
        "print(\"Chosen action:\", action)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XtIQ0Rti1gm"
      },
      "source": [
        "## Task 2: Demonstrate the effectiveness of the RL agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djBEShf0kGI4"
      },
      "source": [
        "For this task, use the agent developed in Task 1 to play the game for 100 episodes (refer to tutorial for how to play a round), record the cumulative reward for each round, and plot the reward for each round. A sample plotting code is given below. Note that you must include code to play for 100 episodes and use the code to obtain round_results for plotting. DO NOT record the round results in advance and paste the results to the notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 207,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "RZrCKywQi6CE",
        "outputId": "468fc0d1-f1f1-49c3-f1cf-ed122db3b891"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "env = gym.make(\"CartPole-v1\")\n",
        "num_episodes = 100\n",
        "\n",
        "episode_results = []\n",
        "for episode in range(num_episodes):\n",
        "  done = False\n",
        "  cumulative_reward = 0\n",
        "\n",
        "  observation = env.reset() #restart game\n",
        "\n",
        "  while not done:\n",
        "    action = Q_Learning_RL_Agent(observation)\n",
        "    observation, reward, done, info = env.step(action)\n",
        "    cumulative_reward += reward\n",
        "  episode_results.append(cumulative_reward)\n",
        "\n",
        "episode_results = np.array(episode_results)\n",
        "plt.plot(episode_results)\n",
        "plt.title('Cumulative reward for each episode')\n",
        "plt.ylabel('Cumulative reward')\n",
        "plt.xlabel('episode')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XndSYH7wlvn7"
      },
      "source": [
        "Print the average reward over the 100 episodes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 208,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOiOp9OYlo5Y",
        "outputId": "a26af7d1-bf40-4436-d673-14a9639cb72d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average cumulative reward: 500.0\n",
            "Is my agent good enough? True\n"
          ]
        }
      ],
      "source": [
        "print(\"Average cumulative reward:\", episode_results.mean())\n",
        "print(\"Is my agent good enough?\", episode_results.mean() > 195)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yg0DCT38lFA6"
      },
      "source": [
        "## Task 3: Render one episode played by the agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vx1awMr9lc_w"
      },
      "source": [
        "Plug your agent to the code below to obtain rendered result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 209,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "id": "LYyavfbIa47D",
        "outputId": "0181d153-bbf6-4b3c-e382-c9211017fde7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial observation: [ 0.02966258  0.03072034  0.02521789 -0.04590504]\n",
            "Cumulative reward for this round: 500.0\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<video alt=\"test\" autoplay \n",
              "                loop controls style=\"height: 400px;\">\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "env1 = gym.make(\"CartPole-v1\")\n",
        "env1._max_episode_steps = 500\n",
        "\n",
        "env = RecordVideo(env1, \"./video\")\n",
        "observation = env.reset()\n",
        "print(\"Initial observation:\", observation) \n",
        "cumulative_reward = 0\n",
        "while True:\n",
        "    env.render()\n",
        "\n",
        "    #your agent goes here\n",
        "    action = Q_Learning_RL_Agent(observation)\n",
        "    observation, reward, done, info = env.step(action) \n",
        "    cumulative_reward += reward\n",
        "    if done: \n",
        "      break;\n",
        "    \n",
        "\n",
        "print(\"Cumulative reward for this round:\", cumulative_reward)    \n",
        "env.close()\n",
        "show_video()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
